# ETL-SD
import pandas as pd
import sqlite3
import logging
from datetime import datetime

# ---------------------------------------------------------
# ğŸ“ CONFIGURAÃ‡ÃƒO DE LOGS E PARÃ‚METROS
# ---------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

CONFIG = {
    "input_file": "dados.csv",
    "db_path": "meu_banco.db",
    "table_name": "vendas"
}

# ---------------------------------------------------------
# ğŸ” ETAPA 1 â€” EXTRACT
# ---------------------------------------------------------
def extract(path: str) -> pd.DataFrame:
    logging.info("â–¶ï¸ Iniciando extraÃ§Ã£o de dados...")

    try:
        df = pd.read_csv(path)
        logging.info(f"ğŸ“„ {len(df)} registros extraÃ­dos.")
    except Exception as e:
        logging.error(f"âŒ Erro ao extrair dados: {e}")
        raise

    return df


# ---------------------------------------------------------
# ğŸ”§ ETAPA 2 â€” TRANSFORM
# ---------------------------------------------------------
def transform(df: pd.DataFrame) -> pd.DataFrame:
    logging.info("ğŸ”§ Iniciando transformaÃ§Ã£o...")

    # PadronizaÃ§Ã£o
    df.columns = [c.lower().strip() for c in df.columns]

    # RemoÃ§Ã£o de duplicados
    before = len(df)
    df = df.drop_duplicates()
    logging.info(f"ğŸ§¹ Removidos {before - len(df)} registros duplicados.")

    # Limpeza de nulos
    df = df.dropna(how="any")

    # ConversÃµes inteligentes
    if "data" in df.columns:
        df["data"] = pd.to_datetime(df["data"], errors="coerce")

    # Novas mÃ©tricas
    if "preco" in df.columns and "quantidade" in df.columns:
        df["valor_total"] = df["preco"] * df["quantidade"]

    # ValidaÃ§Ã£o simples
    if df.isnull().sum().sum() > 0:
        logging.warning("âš ï¸ Ainda existem valores nulos apÃ³s transformaÃ§Ã£o.")

    logging.info("âœ”ï¸ TransformaÃ§Ã£o concluÃ­da.")
    return df


# ---------------------------------------------------------
# ğŸ“¦ ETAPA 3 â€” LOAD (UPERT: UPDATE + INSERT)
# ---------------------------------------------------------
def load(df: pd.DataFrame, db_path: str, table_name: str):
    logging.info("ğŸ“¦ Iniciando carga dos dados...")

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        # Criar tabela se nÃ£o existir
        df.to_sql(table_name, conn, if_exists="append", index=False)

        logging.info(f"âœ”ï¸ {len(df)} registros carregados em '{table_name}'.")
    except Exception as e:
        logging.error(f"âŒ Erro na carga: {e}")
        raise
    finally:
        conn.close()


# ---------------------------------------------------------
# ğŸš€ PIPELINE COMPLETO
# ---------------------------------------------------------
def run_etl(config=CONFIG):
    logging.info("ğŸš€ Pipeline ETL iniciado...")

    df = extract(config["input_file"])
    df = transform(df)
    load(df, config["db_path"], config["table_name"])

    logging.info("ğŸ Pipeline ETL finalizado com sucesso.")


# Executar
if __name__ == "__main__":
    run_etl()
